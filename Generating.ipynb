{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPn3nOtAIi21sJ4+9ly+9Y7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SnehalYu/Query-Auto-Completion-/blob/main/Generating.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating text\n",
        "from typing import List\n",
        "def get_next_character(context:List, k:int=3):\n",
        "    assert k>=1\n",
        "    bigram = tuple(context[-2:])\n",
        "    if bigram in dict_two:\n",
        "        probabilities = table[dict_bi_to_num[bigram]]\n",
        "    else:\n",
        "        probabilities = 1/table.shape[1] * np.ones(table.shape[1])\n",
        "        # raise NotImplementedError\n",
        "        '''\n",
        "        take any 5 characters, with prob = 1/num_of_characters\n",
        "        '''\n",
        "        pass\n",
        "    top_indices = np.argsort(probabilities)[-k:]\n",
        "    top_probs = probabilities[top_indices]\n",
        "    top_probs = np.log(top_probs)\n",
        "    next_char = [characters[ind] for ind in top_indices]\n",
        "    next_char.reverse()\n",
        "    top_probs = list(top_probs)\n",
        "    top_probs.reverse()\n",
        "    return next_char, top_probs\n",
        "\n",
        "\n",
        "def generate_text(starting_context, max_length=10, num_completions=5, topk=3):\n",
        "    possible_completions = [starting_context]\n",
        "    probs = [0.0]\n",
        "    context = starting_context\n",
        "    # for _ in range(max_length-2):\n",
        "    for _ in range(max_length-2):\n",
        "        prob_completions_ = []\n",
        "        possible_completions_ = []\n",
        "        for completion,prob in zip(possible_completions, probs):\n",
        "            ## add termination condition here in if\n",
        "            if completion[-1] in ['</s>','\\n','.'] :\n",
        "                possible_completions_.extend([completion] )\n",
        "                prob_completions_.extend([prob])\n",
        "                # print('end case')\n",
        "            else:\n",
        "                next_char, top_probs = get_next_character(completion, k=topk)\n",
        "                # print('context: ',completion,'next chars: ', str(next_char))\n",
        "                possible_completions_.extend([completion+[char] for char in next_char] )\n",
        "                prob_completions_.extend( [prob+prob_ for prob_ in top_probs])\n",
        "        # select most probables\n",
        "        prob_completions_ = np.array(prob_completions_)\n",
        "        max_prob_indices = np.argsort(prob_completions_)[-num_completions:]\n",
        "        possible_completions = [possible_completions_[ind] for ind in max_prob_indices]\n",
        "        # print('possible completions:',possible_completions)\n",
        "        probs = list(prob_completions_[max_prob_indices])\n",
        "    possible_completions = [''.join(x) for x in possible_completions]\n",
        "    return possible_completions, probs\n",
        "\n",
        "\n",
        "userQuery = \"gb\"\n",
        "maxLength = 10\n",
        "starting_context = ['g','b']\n",
        "generated_text, _ = generate_text(starting_context, maxLength)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNP8Fs2V2_wI",
        "outputId": "eae3aa95-97f6-40b5-995b-c9e09fc928b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['gboo comer', 'gboo comes', 'gbrics\\n', 'gboo com\\n', 'gboo\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCzxfSpIgg5S"
      },
      "outputs": [],
      "source": []
    }
  ]
}